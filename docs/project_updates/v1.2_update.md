# 📢 CORI Update – v1.2
Date:</strong> June 16, 2025

Progressed toward the MVP for <strong>physical-to-symbolic color mapping and virtual sorting</strong>. CORI now scans real-world items (e.g., a red shirt), classifies their dominant color via OpenCV, and logs symbolic sorting decisions. The Gazebo world is configured to support this logic with bins and object placement.

<table>
<tr>
<td>

<h2>✅ Achievements</h2>

<h3>🤖 URDF Rebuild & Cleanup</h3>
<ul>
<li>Rebuilt <code>cori.urdf.xacro</code> with full link/joint tree, inertials, and macro-generated fingers</li>
<li>Resolved link duplication, standardized naming, ensured ROS 2 + Gazebo compatibility</li>
</ul>

<h3>🚀 Launch System Refactor</h3>
<ul>
<li>Created clean ROS 2 launch config integrating CORI’s URDF, Gazebo world, and RViz visualization</li>
</ul>

<h3>🌍 Laundry World Complete</h3>
<ul>
<li><code>laundry_world.sdf</code> includes:</li>
<ul>
<li>🧺 Bins: <code>laundry_bin_lights</code>, <code>laundry_bin_darks</code>, <code>laundry_bin_colors</code></li>
<li>👕 Clothing props: <code>sock_white</code>, <code>sock_dark</code>, <code>shirt_green</code>, etc.</li>
<li>🪑 Table layout for object placement</li>
<li>🧍 CORI robot facing table with proper ground contact</li>
</ul>
</ul>

<img src="https://github.com/J-Uptegraph/CORI/blob/main/assets/imgs/CORI_Gazebo_Sim_v1.png" width="1080px"/>

---

<h2>🎯 MVP Goal</h2>

Enable CORI to:
<ol>
<li>Scan a real-world item via webcam using <code>cori_cv</code></li>
<li>Detect dominant color using OpenCV</li>
<li>Publish label to ROS 2 / Gazebo</li>
<li>Map to a matching virtual cloth object</li>
<li>Simulate sorting into correct bin</li>
</ol>

<strong>System Flow:</strong><br>
<code>Webcam → OpenCV Node → ROS 2 Message → Gazebo Cloth Proxy → Virtual Sorter</code>

---

<h2>🔧 Next Steps</h2>

<h3>👁️ Perception</h3>
<ul>
<li>[ ] Finalize <code>laundry_color_detection.py</code> classification logic (HSV or RGB)</li>
<li>[ ] Publish color labels as ROS 2 messages (e.g., <code>"red"</code>)</li>
</ul>

<h3>🌐 Virtual Bridge</h3>
<ul>
<li>[ ] Develop ROS 2 node to map labels to Gazebo clothing proxies</li>
<li>[ ] Highlight or log selected item in simulation</li>
</ul>

<h3>🤖 Robotic Sorting</h3>
<ul>
<li>[ ] Prototype pick-and-place logic using CORI’s simulated arm</li>
<li>[ ] Add <code>gazebo_ros2_control</code> plugin for gripper actuation</li>
</ul>

<h3>🧩 System Integration</h3>
<ul>
<li>[ ] Finalize launch stack (vision + sim + message bridge)</li>
<li>[ ] (Optional) Add OpenCV GUI overlay with bounding boxes + category label</li>
</ul>

---

<h3>🧠 Symbolic Detection Live</h3>
<ul>
<li><code>laundry_color_detection.py</code> detects dominant clothing color in real time</li>
<li>Console Output: <code>SORT: RED SCANNED → INTO PILE: COLORS</code></li>
</ul>

<h3>🧩 Modular Architecture</h3>
<ul>
<li>Pipeline is decoupled and modular—ready for ROS 2 integration and testing</li>
<li>Scalable design for multi-object symbolic reasoning</li>
</ul>

</td>
</tr>
</table>
